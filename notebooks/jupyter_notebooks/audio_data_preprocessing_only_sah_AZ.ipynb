{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399bcf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt update\n",
    "# !apt -y install ffmpeg\n",
    "\n",
    "# Install this part from terminal using sudo for the password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ce690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "# from tqdm.auto import tqdm\n",
    "from tqdm.autonotebook import tqdm as notebook_tqdm\n",
    "notebook_tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa7dc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b158141",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = cwd.removesuffix('notebooks/jupyter_notebooks')\n",
    "root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ea3394",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(root_path + 'raw_data/training_data/asr.csv') #your dataset here\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24b5b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_lang = list(df['lang'].unique()) \n",
    "list_lang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfec434",
   "metadata": {},
   "source": [
    "'xas' has around 75000 entries, so we skip it for the processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f119b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_lang = ['bak', 'evn', 'mhr', 'tat', 'sah']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba69eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_dir = root_path + 'processed_data' #new directory for cut files\n",
    "if os.path.exists(new_dir) is False:\n",
    "    os.mkdir(new_dir)\n",
    "else:\n",
    "    print('folder already exists')\n",
    "    \n",
    "list_lang = list(df['lang'].unique())    \n",
    "    \n",
    "# Create sub-folders with respective lang codes    \n",
    "    \n",
    "for l in list_lang:\n",
    "    \n",
    "    new_dir_ext = new_dir + f'/{l}'\n",
    "    \n",
    "    if os.path.exists(new_dir_ext) is False:\n",
    "        os.mkdir(new_dir_ext)\n",
    "    else:\n",
    "        print('folder already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34edc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"fpath\"] = root_path + 'raw_data/training_data/' + df[\"source\"].astype(str)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca995fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacer(path):\n",
    "    return path.replace(' ', '_')\n",
    "df['fpath'] = df['fpath'].apply(replacer)\n",
    "df = df.reset_index() #adding indexes(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4de1591",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {root_path}/processed_data/ffmpeg_log\n",
    "\n",
    "def cutter(row): # cutting files accroding to timecodes\n",
    "    \n",
    "    fpath, start, end, index, lang = row[\"fpath\"], row[\"start\"], row[\"end\"], row[\"index\"], row[\"lang\"]\n",
    "    \n",
    "    if pd.isna(row.transcription) == False:    \n",
    "        \n",
    "        if pd.isna(row.start) or pd.isna(row.end):\n",
    "            \n",
    "            !ffmpeg -n -i {fpath} -ar 16000 \\\n",
    "            {root_path + 'processed_data/' + str(lang) + \"/\" + str(index)}.mp3 \\\n",
    "            2> {root_path}/processed_data/ffmpeg_log/{index}.log\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            !ffmpeg -n -i {fpath} -ss {str(start)} -to {str(end)} -ar 16000 \\\n",
    "            {root_path + 'processed_data/' + str(lang) + \"/\" + str(index)}.mp3 \\\n",
    "            2> {root_path}/processed_data/ffmpeg_log/{index}.log\n",
    "\n",
    "            \n",
    "for l in ['sah']:\n",
    "    \n",
    "    df_l = df[df['lang']==l]\n",
    "    df_l.progress_apply(cutter, axis=1)\n",
    "    \n",
    "    df_l = df_l.dropna(subset=['transcription'])\n",
    "    \n",
    "    # making column for paths of cut files\n",
    "    df_l['file_name'] = df_l['index'].apply(lambda x: str(x) + '.mp3')\n",
    "    \n",
    "    \n",
    "    # cleaning transcriptions\n",
    "    # df_l['transcription_clean'] = df_l['transcription'].apply(lambda x: x.strip('.«,').replace('=', '').replace(' ', '').replace('Ø', ' ')\n",
    "    df_l['transcription_clean'] = df_l['transcription'].apply(lambda x: x.strip('.«,').replace('=', '').replace('Ø', ' ')) # clearing punctuation marks and spaces\n",
    "    df_l['transcription_clean'] = df_l['transcription_clean'].apply(lambda x: re.sub('\\(.+?\\)', '', x))\n",
    "   \n",
    "    # filling empty strings\n",
    "    df_l['transcription_clean'] = df_l['transcription_clean'].apply(lambda s: s if s else '-')\n",
    "        \n",
    "    # saving file\n",
    "    df_l.to_csv(f'{root_path}/processed_data/{l}/asr_{l}.csv', index=False)\n",
    "    \n",
    "    # dropping columns which are not needed in the metadata file\n",
    "    df_l.drop(columns=['fpath', 'id', 'start', 'end', 'index', 'source', 'lang'], inplace=True)\n",
    "    \n",
    "    df_l = df_l[['file_name', 'transcription']]\n",
    "    df_l.to_csv(f'{root_path}/processed_data/{l}/metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc25165f",
   "metadata": {},
   "source": [
    "Some analysis for Evenki language transcripts : we have 4 cases where the person speaks only Russian, so transcription is set to NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fbcecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evn = df[df['lang'] == 'evn']\n",
    "\n",
    "num_mask = pd.to_numeric(df_evn['transcription'], errors='coerce').isnull()\n",
    "\n",
    "df_evn.loc[num_mask, 'transcription']\n",
    "\n",
    "print(df_evn.transcription[df_evn.transcription.isna()]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8212b14a",
   "metadata": {},
   "source": [
    "Some analysis for Bashkir Language transcripts : we have cases where start and end of recording are set to NaN, this is for very short audio, i.e. there is no need to cut the audio --> in the preprocessing we don't cut and skip them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1add01ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bak = df[df['lang'] == 'bak']\n",
    "\n",
    "print(df_bak.start[df_bak.start.isna()]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19ac7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_mask = pd.to_numeric(df_bak['transcription'], errors='coerce').isnull()\n",
    "\n",
    "df_bak.loc[num_mask, 'transcription']\n",
    "\n",
    "print(df_bak.transcription[df_bak.transcription.isna()]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34071fc3",
   "metadata": {},
   "source": [
    "Some analysis for Tatar language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3a9ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tat = df[df['lang'] == 'tat']\n",
    "\n",
    "print(df_tat.start[df_tat.start.isna()]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d03e7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_mask = pd.to_numeric(df_tat['transcription'], errors='coerce').isnull()\n",
    "\n",
    "df_tat.loc[num_mask, 'transcription']\n",
    "\n",
    "print(df_tat.transcription[df_tat.transcription.isna()]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b82e1d",
   "metadata": {},
   "source": [
    "After this audio cutting procedure also all the audio files are normalized to have 16Hz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
