{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport os\nimport re\nfrom tqdm.auto import tqdm\ntqdm.pandas()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-01T11:17:32.392852Z","iopub.execute_input":"2022-12-01T11:17:32.393340Z","iopub.status.idle":"2022-12-01T11:17:32.447584Z","shell.execute_reply.started":"2022-12-01T11:17:32.393234Z","shell.execute_reply":"2022-12-01T11:17:32.446726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!apt update\n!pip install transformers datasets phonemizer -y\n!apt install espeak -y\n!pip install pydub -y\n!pip install transformers --upgrade -y\n!pip install torchaudio -y\n!pip install tqdm --upgrade -y\n!pip install torchaudio --upgrade -y","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:17:32.450659Z","iopub.execute_input":"2022-12-01T11:17:32.450930Z","iopub.status.idle":"2022-12-01T11:17:48.088878Z","shell.execute_reply.started":"2022-12-01T11:17:32.450905Z","shell.execute_reply":"2022-12-01T11:17:48.087631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!add-apt-repository -y ppa:jonathonf/ffmpeg-4\n!apt update\n!apt install -y ffmpeg","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:17:48.090742Z","iopub.execute_input":"2022-12-01T11:17:48.091505Z","iopub.status.idle":"2022-12-01T11:17:58.734584Z","shell.execute_reply.started":"2022-12-01T11:17:48.091461Z","shell.execute_reply":"2022-12-01T11:17:58.733428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import __version__ as transformers_ver\nfrom tqdm import __version__ as tqdm_ver\nfrom torch import __version__ as torch_ver\nfrom torchaudio import __version__ as torchaudio_ver\nfrom pandas import __version__ as pd_ver\nprint(f\"transformers_ver:\\t{transformers_ver}\")\nprint(f\"tqdm_ver:\\t{tqdm_ver}\")\nprint(f\"torch_ver:\\t{torch_ver}\")\nprint(f\"torchaudio_ver:\\t{torchaudio_ver}\")\nprint(f\"pandas_ver:\\t{pd_ver}\")","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:17:58.739784Z","iopub.execute_input":"2022-12-01T11:17:58.740126Z","iopub.status.idle":"2022-12-01T11:17:59.370104Z","shell.execute_reply.started":"2022-12-01T11:17:58.740096Z","shell.execute_reply":"2022-12-01T11:17:59.369001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install phonemizer","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:17:59.371720Z","iopub.execute_input":"2022-12-01T11:17:59.372585Z","iopub.status.idle":"2022-12-01T11:18:08.710620Z","shell.execute_reply.started":"2022-12-01T11:17:59.372540Z","shell.execute_reply":"2022-12-01T11:18:08.709356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForCTC, Wav2Vec2Processor\n\n# model = AutoModelForCTC.from_pretrained(\"facebook/wav2vec2-xlsr-53-espeak-cv-ft\")\nprocessor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-xlsr-53-espeak-cv-ft\")","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:18:08.712526Z","iopub.execute_input":"2022-12-01T11:18:08.713270Z","iopub.status.idle":"2022-12-01T11:18:11.303941Z","shell.execute_reply.started":"2022-12-01T11:18:08.713229Z","shell.execute_reply":"2022-12-01T11:18:11.302616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForCTC.from_pretrained(\"facebook/wav2vec2-xlsr-53-espeak-cv-ft\")","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:18:11.305729Z","iopub.execute_input":"2022-12-01T11:18:11.306136Z","iopub.status.idle":"2022-12-01T11:19:13.720383Z","shell.execute_reply.started":"2022-12-01T11:18:11.306091Z","shell.execute_reply":"2022-12-01T11:19:13.718617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/tat-asr/tat/asr_tat.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:19:13.733687Z","iopub.execute_input":"2022-12-01T11:19:13.734675Z","iopub.status.idle":"2022-12-01T11:19:14.004429Z","shell.execute_reply.started":"2022-12-01T11:19:13.734612Z","shell.execute_reply":"2022-12-01T11:19:14.003474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['fpath'] = df['file_name'].map(lambda x: '/kaggle/input/tat-asr/tat/' + x)\ndf['fpath']","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:19:14.008651Z","iopub.execute_input":"2022-12-01T11:19:14.010970Z","iopub.status.idle":"2022-12-01T11:19:15.494615Z","shell.execute_reply.started":"2022-12-01T11:19:14.010929Z","shell.execute_reply":"2022-12-01T11:19:15.493612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\ndevice = torch.device(f\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:19:15.496168Z","iopub.execute_input":"2022-12-01T11:19:15.496550Z","iopub.status.idle":"2022-12-01T11:19:15.653697Z","shell.execute_reply.started":"2022-12-01T11:19:15.496515Z","shell.execute_reply":"2022-12-01T11:19:15.652776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchaudio\nfrom tqdm.auto import tqdm\ntqdm.pandas()\ndevice = torch.device(f\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = model.to(device)\n\ndef recognizer(fpath):\n    try:\n        waveform, sample_rate = torchaudio.load(fpath)\n        waveform = waveform.to(device)\n        logits = model(waveform).logits\n        pred_ids = torch.argmax(logits, dim=-1)\n        pred_str = processor.batch_decode(pred_ids)[0]\n        return pred_str\n    except:\n        return 0","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:19:15.657109Z","iopub.execute_input":"2022-12-01T11:19:15.657723Z","iopub.status.idle":"2022-12-01T11:19:18.958603Z","shell.execute_reply.started":"2022-12-01T11:19:15.657693Z","shell.execute_reply":"2022-12-01T11:19:18.956986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['recognized'] = df['fpath'].progress_apply(recognizer)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:19:18.962847Z","iopub.execute_input":"2022-12-01T11:19:18.966095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['recognized'][0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install abydos\n\nimport abydos\n\nfrom abydos import distance\n\nphonetic = distance.PhoneticEditDistance()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"phonetic = distance.PhoneticEditDistance()\ndef phonetic_metric(row):\n    try:\n        result = phonetic.dist(row['transcription'], row['recognized'])\n        return result\n    except Exception as e:\n        print(e)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['phonetic_ev'] = df.progress_apply(phonetic_metric, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[['transcription', 'recognized', 'phonetic_ev']].sample(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.phonetic_ev.plot.hist(bins=20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.phonetic_ev.mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def recognizer_adv(fpath):\n    try:\n        waveform, sample_rate = torchaudio.load(fpath)\n        waveform = waveform.to(device)\n        logits = model(waveform).logits\n        pred_ids = torch.argmax(logits, dim=-1)\n        pred_str = processor.batch_decode(pred_ids, uselexicon=true)[0]\n        return pred_str\n    except:\n        return 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def phonetic_metric_adv(row):\n    try:\n        result = phonetic.dist(row['transcription'], row['recognized_adv'])\n        return result\n    except Exception as e:\n        print(e)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['phonetic_ev_adv'] = df.progress_apply(phonetic_metric_adv, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[['transcription', 'recognized_adv', 'phonetic_ev_adv']].sample(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}